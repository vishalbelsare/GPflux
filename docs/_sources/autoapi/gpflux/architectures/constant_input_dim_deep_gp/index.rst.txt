:py:mod:`gpflux.architectures.constant_input_dim_deep_gp`
=========================================================

.. py:module:: gpflux.architectures.constant_input_dim_deep_gp

.. autoapi-nested-parse::

   This module provides :func:`build_constant_input_dim_deep_gp` to build a Deep GP of
   arbitrary depth where each hidden layer has the same input dimensionality as the data.



Module Contents
---------------

.. py:class:: Config

   The configuration used by :func:`build_constant_input_dim_deep_gp`.

   .. py:attribute:: num_inducing
      :annotation: :int

      The number of inducing variables, *M*. The Deep GP uses the same number
      of inducing variables in each layer.


   .. py:attribute:: inner_layer_qsqrt_factor
      :annotation: :float

      A multiplicative factor used to rescale the hidden layers'
      :attr:`~gpflux.layers.GPLayer.q_sqrt`. Typically this value is chosen to be small
      (e.g., 1e-5) to reduce noise at the start of training.


   .. py:attribute:: likelihood_noise_variance
      :annotation: :float

      The variance of the :class:`~gpflow.likelihoods.Gaussian` likelihood that is used
      by the Deep GP.


   .. py:attribute:: whiten
      :annotation: :bool = True

      Determines the parameterisation of the inducing variables.
      If `True`, :math:``p(u) = N(0, I)``, otherwise :math:``p(u) = N(0, K_{uu})``.
      .. seealso:: :attr:`gpflux.layers.GPLayer.whiten`



.. py:function:: _construct_kernel(input_dim: int, is_last_layer: bool) -> gpflow.kernels.SquaredExponential

   Return a :class:`gpflow.kernels.SquaredExponential` kernel with ARD lengthscales set to
   2 and a small kernel variance of 1e-6 if the kernel is part of a hidden layer;
   otherwise, the kernel variance is set to 1.0.

   :param input_dim: The input dimensionality of the layer.
   :param is_last_layer: Whether the kernel is part of the last layer in the Deep GP.


.. py:function:: build_constant_input_dim_deep_gp(X: numpy.ndarray, num_layers: int, config: Config) -> gpflux.models.DeepGP

   Build a Deep GP consisting of ``num_layers`` :class:`GPLayer`\ s.
   All the hidden layers have the same input dimension as the data, that is, ``X.shape[1]``.

   The architecture is largely based on :cite:t:`salimbeni2017doubly`, with
   the most notable difference being that we keep the hidden dimension equal
   to the input dimensionality of the data.

   .. note::
       This architecture might be slow for high-dimensional data.

   .. note::
       This architecture assumes a :class:`~gpflow.likelihoods.Gaussian` likelihood
       for regression tasks. Specify a different likelihood for performing
       other tasks such as classification.

   :param X: The training input data, used to retrieve the number of datapoints and
       the input dimension and to initialise the inducing point locations using k-means. A
       tensor of rank two with the dimensions ``[num_data, input_dim]``.
   :param num_layers: The number of layers in the Deep GP.
   :param config: The configuration for (hyper)parameters. See :class:`Config` for details.


